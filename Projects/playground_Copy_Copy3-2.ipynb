{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCw1JpV0_qPm"
   },
   "source": [
    "# Load dataset\n",
    "\n",
    "Data format:\n",
    "\n",
    "|id|word_seq|tag_seq|\n",
    "|:--|:--|:--|\n",
    "|index of the sentence|tokenized words|corresponding NER tags|\n",
    "|0|`[\"protection\", \"calves\", ...]`|`[\"O\", \"LIVESTOCK\", ...]`|\n",
    "|1|`[\"prevent\", \"diarrhea\",...]` |`[\"O\", \"DISEASE_OR_SYNDROME\", ...]`|\n",
    "|...|...|...|\n",
    "\n",
    "\n",
    "\n",
    "There are 64 categories of NER tags (plus 1 padding token).\n",
    "\n",
    "The ground-truth tags are provided for the training and testing set, while being omitted in the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8HqA-g6_qPu",
    "outputId": "f2cd1415-6436-4fab-f145-3d738146d0bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys in train_dict: dict_keys(['id', 'word_seq', 'tag_seq'])\n",
      "keys in val_dict: dict_keys(['id', 'word_seq', 'tag_seq'])\n",
      "keys in test_dict: dict_keys(['id', 'word_seq'])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "train_dict = pkl.load(open(\"data/train.pkl\", \"rb\"))\n",
    "val_dict = pkl.load(open(\"data/val.pkl\", \"rb\"))\n",
    "test_dict = pkl.load(open(\"data/test.pkl\", \"rb\"))\n",
    "print(\"keys in train_dict:\", train_dict.keys())\n",
    "print(\"keys in val_dict:\", val_dict.keys())\n",
    "print(\"keys in test_dict:\", test_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h4M5eoQh_qP-",
    "outputId": "9c11ae4c-3d85-4f2d-d225-1c625fc63dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "('Protection', 'O') ('of', 'O') ('calves', 'LIVESTOCK') ('against', 'O') ('fatal', 'O') ('enteric', 'DISEASE_OR_SYNDROME') ('colibacillosis', 'DISEASE_OR_SYNDROME') ('by', 'O') ('orally', 'GENE_OR_GENOME') ('administered', 'GENE_OR_GENOME') ('Escherichia', 'GENE_OR_GENOME') ('coli', 'GENE_OR_GENOME') ('K99', 'GENE_OR_GENOME') ('-', 'O') ('specific', 'CARDINAL') ('monoclonal', 'CARDINAL') ('antibody', 'CARDINAL') ('.', 'O') ('A', 'O') ('monoclonal', 'CHEMICAL') ('antibody', 'CHEMICAL') ('(', 'O') ('MCA', 'GENE_OR_GENOME') (')', 'O') ('to', 'O') ('enterotoxigenic', 'CHEMICAL') ('Escherichia', 'CHEMICAL') ('coli', 'CHEMICAL') ('K99', 'O') ('antigen', 'O') ('agglutinated', 'O') ('K99+', 'GENE_OR_GENOME') ('enterotoxigenic', 'GENE_OR_GENOME') ('E', 'GENE_OR_GENOME') ('.', 'O') ('coli', 'CHEMICAL') ('strains', 'CHEMICAL') ('B44', 'CHEMICAL') ('(', 'O') ('O9', 'O') (':', 'O') ('K30', 'O') (';', 'O') ('K99', 'O') (';', 'O') ('F41', 'O') (':', 'O') ('H-', 'O') (')', 'O') ('and', 'O') ('B41', 'CHEMICAL') ('(', 'O') ('O101', 'PRODUCT') (':', 'O') ('K99', 'O') (';', 'O') ('F41', 'O') (':', 'O') ('H-', 'O') (')', 'O') ('grown', 'O') ('at', 'O') ('37', 'QUANTITY') ('degrees', 'QUANTITY') ('C', 'O') ('but', 'O') ('not', 'O') ('at', 'O') ('18', 'QUANTITY') ('degrees', 'QUANTITY') ('C.', 'O') ('The', 'O') ('MCA', 'GENE_OR_GENOME') (',', 'O') ('which', 'O') ('was', 'O') ('characterized', 'O') ('as', 'O') ('immunoglobulin', 'GENE_OR_GENOME') ('G1', 'GENE_OR_GENOME') (',', 'O') ('reacted', 'O') ('specifically', 'O') ('with', 'O') ('K99', 'CHEMICAL') ('antigen', 'CHEMICAL') ('in', 'O') ('an', 'O') ('enzyme-linked', 'CHEMICAL') ('immunosorbent', 'CHEMICAL') ('assay', 'CHEMICAL') ('and', 'O') ('precipitated', 'O') ('radiolabeled', 'O') ('K99', 'CHEMICAL') ('antigen', 'CHEMICAL') ('.', 'O') ('A', 'O') ('total', 'O') ('of', 'O') ('45', 'O') ('colostrum', 'CHEMICAL') ('-fed', 'O') ('and', 'O') ('colostrum', 'CHEMICAL') ('-deprived', 'O') ('calves', 'LIVESTOCK') ('were', 'O') ('used', 'O') ('in', 'O') ('three', 'CARDINAL') ('separate', 'O') ('trials', 'O') ('to', 'O') ('determine', 'O') ('whether', 'O') ('the', 'O') ('orally', 'O') ('administered', 'O') ('K99-specific', 'O') ('MCA', 'GENE_OR_GENOME') ('would', 'O') ('prevent', 'O') ('diarrhea', 'DISEASE_OR_SYNDROME') ('caused', 'O') ('by', 'O') ('strain', 'O') ('B44', 'GENE_OR_GENOME')\n"
     ]
    }
   ],
   "source": [
    "# an entry of the dataset\n",
    "print(\"index:\", train_dict[\"id\"][0])\n",
    "print(*zip(train_dict[\"word_seq\"][0], train_dict[\"tag_seq\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPyI06dt_qQH",
    "outputId": "08773087-7818-4ac9-89ef-0d7168341ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of the NER tags: 65\n",
      "all the NER tags: {'ORDINAL', 'DISEASE_OR_SYNDROME', 'WILDLIFE', 'MACHINE_ACTIVITY', 'FOOD', 'CELL_OR_MOLECULAR_DYSFUNCTION', 'MATERIAL', 'PERSON', 'SIGN_OR_SYMPTOM', 'INDIVIDUAL_BEHAVIOR', 'RESEARCH_ACTIVITY', 'ORGAN_OR_TISSUE_FUNCTION', 'THERAPEUTIC_OR_PREVENTIVE_PROCEDURE', 'VIRUS', 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS', 'CORONAVIRUS', 'VIRAL_PROTEIN', 'INJURY_OR_POISONING', 'LABORATORY_OR_TEST_RESULT', 'TIME', 'EUKARYOTE', 'ANATOMICAL_STRUCTURE', 'ORGANISM', 'EVENT', 'DATE', 'PERCENT', '_t_pad_', 'CELL', 'NORP', 'EVOLUTION', 'IMMUNE_RESPONSE', 'GENE_OR_GENOME', 'TISSUE', 'LIVESTOCK', 'CARDINAL', 'ARCHAEON', 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY', 'PRODUCT', 'PHYSICAL_SCIENCE', 'SOCIAL_BEHAVIOR', 'EXPERIMENTAL_MODEL_OF_DISEASE', 'LOC', 'LAW', 'BACTERIUM', 'CHEMICAL', 'O', 'MOLECULAR_FUNCTION', 'SUBSTRATE', 'MONEY', 'CELL_FUNCTION', 'QUANTITY', 'GROUP_ATTRIBUTE', 'LABORATORY_PROCEDURE', 'BODY_PART_ORGAN_OR_ORGAN_COMPONENT', 'WORK_OF_ART', 'GPE', 'BODY_SUBSTANCE', 'FAC', 'LANGUAGE', 'ORG', 'EDUCATIONAL_ACTIVITY', 'DIAGNOSTIC_PROCEDURE', 'DAILY_OR_RECREATIONAL_ACTIVITY', 'GROUP', 'CELL_COMPONENT'}\n"
     ]
    }
   ],
   "source": [
    "# all the NER tags:\n",
    "from itertools import chain\n",
    "print(\"count of the NER tags:\", len(set(chain(*train_dict[\"tag_seq\"]))))\n",
    "print(\"all the NER tags:\", set(chain(*train_dict[\"tag_seq\"])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7K4U2Oa_qQO"
   },
   "source": [
    "# Prepare the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TVFnLsCH_qQQ",
    "outputId": "dec60809-e1b3-490d-ad3e-865c1644bf0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of word vocab: 82275 size of tag_dict: 65\n"
     ]
    }
   ],
   "source": [
    "# prepare word vocab and tag vocab\n",
    "\n",
    "vocab_dict = {'_unk_': 0, '_w_pad_': 1}\n",
    "\n",
    "for doc in train_dict['word_seq']:\n",
    "    for word in doc:\n",
    "        if(word not in vocab_dict):\n",
    "            vocab_dict[word] = len(vocab_dict)\n",
    "\n",
    "tag_dict = {'_t_pad_': 0} # add a padding token\n",
    "\n",
    "for tag_seq in train_dict['tag_seq']:\n",
    "    for tag in tag_seq:\n",
    "        if(tag not in tag_dict):\n",
    "            tag_dict[tag] = len(tag_dict)\n",
    "word2idx = vocab_dict\n",
    "idx2word = {v:k for k,v in word2idx.items()}\n",
    "tag2idx = tag_dict\n",
    "idx2tag = {v:k for k,v in tag2idx.items()}            \n",
    "\n",
    "print(\"size of word vocab:\", len(vocab_dict), \"size of tag_dict:\", len(tag_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Ckw4DmNx_qQW"
   },
   "outputs": [],
   "source": [
    "# The maximum length of a sentence is set to 128\n",
    "max_sent_length = 128\n",
    "\n",
    "train_tokens = np.array([[word2idx[w] for w in doc] for doc in train_dict['word_seq']])\n",
    "val_tokens = np.array([[word2idx.get(w, 0) for w in doc] for doc in val_dict['word_seq']])\n",
    "test_tokens = np.array([[word2idx.get(w, 0) for w in doc] for doc in test_dict['word_seq']])\n",
    "\n",
    "\n",
    "train_tags = [[tag2idx[t] for t in t_seq] for t_seq in train_dict['tag_seq']]\n",
    "train_tags = np.array([to_categorical(t_seq, num_classes=len(tag_dict)) for t_seq in train_tags])\n",
    "\n",
    "val_tags = [[tag2idx[t] for t in t_seq] for t_seq in val_dict['tag_seq']]\n",
    "val_tags = np.array([to_categorical(t_seq, num_classes=len(tag_dict)) for t_seq in val_tags])\n",
    "\n",
    "# we don't have test tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IxfXxiu_qQb",
    "outputId": "d4bf58d9-3aa5-4cc5-d5c6-49d3bfa1e7e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: (23600, 128) tag size: (23600, 128, 65)\n",
      "validating size: (2950, 128) tag size: (2950, 128, 65)\n"
     ]
    }
   ],
   "source": [
    "print(\"training size:\", train_tokens.shape, \"tag size:\", train_tags.shape)\n",
    "print(\"validating size:\", val_tokens.shape, \"tag size:\", val_tags.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q31n_kFD_qQk",
    "outputId": "1d9157e4-9fdb-48f5-fee5-84c7d394f893"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  4  5  6  7  8  9 10 11] [1 1 2 1 1 3 3 1 4 4]\n"
     ]
    }
   ],
   "source": [
    "# an example of training instance and training tags.\n",
    "print(train_tokens[0,:10], np.argmax(train_tags[0, :10, :], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fSIFiBo9_qQp"
   },
   "outputs": [],
   "source": [
    "num_training_data = train_tokens.shape[0]\n",
    "sequence_length = train_tokens.shape[1]\n",
    "vocabulary_size = len(vocab_dict)\n",
    "num_tags = len(tag_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5v8-QnnN_qQt"
   },
   "outputs": [],
   "source": [
    "drop = 0.3\n",
    "epochs = 20\n",
    "batch_size = 128\n",
    "embedding_dim = 64\n",
    "\n",
    "hidden_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gsr6Gwr6_qQx"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, BatchNormalization, Input, Add, Concatenate,\\\n",
    "    Bidirectional, SimpleRNN, LSTM, GRU, TimeDistributed\n",
    "from keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "7Lz8C_XS_qQ3"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(sequence_length,), dtype='int32')\n",
    "emb_layer = Embedding(input_dim=vocabulary_size, \n",
    "                    output_dim=embedding_dim, \n",
    "                    input_length=sequence_length)\n",
    "embedding = emb_layer(inputs)\n",
    "\n",
    "drop_embed = Dropout(drop)(embedding)\n",
    "\n",
    "lstm_out1 = Bidirectional(LSTM(units=hidden_size, return_sequences=True))(drop_embed)\n",
    "# output: lstm_out -> [batch_size, sequence_length, hidden_size]\n",
    "\n",
    "drop_lstm1 = Dropout(drop)(lstm_out1)\n",
    "\n",
    "lstm_out2 = Bidirectional(LSTM(units=hidden_size, return_sequences=True))(drop_lstm1)\n",
    "# output: lstm_out -> [batch_size, sequence_length, hidden_size]\n",
    "\n",
    "dropout_lstm2 = Dropout(drop)(lstm_out2)\n",
    "\n",
    "\n",
    "outputs = TimeDistributed(Dense(units=num_tags, activation='softmax'))(dropout_lstm2)\n",
    "# output: outputs -> [batch_size, sequence_length, vocabulary_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DyS8qkh6_qQ7",
    "outputId": "4766c8ef-f4ad-4d09-e4ee-1a8291962911"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 128, 64)           5265600   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128, 64)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128, 128)          66048     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128, 128)          98816     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128, 128)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 128, 65)           8385      \n",
      "=================================================================\n",
      "Total params: 5,438,849\n",
      "Trainable params: 5,438,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam,metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "mPa9NmnfBVeC"
   },
   "outputs": [],
   "source": [
    "checkpointer = keras.callbacks.ModelCheckpoint(\n",
    "    filepath=os.path.join(\"models\", \"weights.hdf5\"),\n",
    "    monitor=\"val_accuracy\",\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "earlystopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J0HXfVpM_qRB",
    "outputId": "ebb2307c-387d-4d98-e270-d82005db04d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning Model...\n",
      "Epoch 1/20\n",
      " 85/166 [==============>...............] - ETA: 3:34 - loss: 1.6013 - accuracy: 0.7517"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " [_Derived_]  OOM when allocating tensor with shape[128,128,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradients/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[StatefulPartitionedCall_3]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_11100]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-86739ba68126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Traning Model...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mtrain_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtrain_tags\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1660\u001b[0m     \"\"\"\n\u001b[1;32m-> 1661\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    591\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  [_Derived_]  OOM when allocating tensor with shape[128,128,64] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node gradients/TensorArrayUnstack/TensorListFromTensor_grad/TensorListStack}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[StatefulPartitionedCall_3]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_11100]\n\nFunction call stack:\ntrain_function -> train_function -> train_function\n"
     ]
    }
   ],
   "source": [
    "print(\"Traning Model...\")\n",
    "history = model.fit(\n",
    "        train_tokens, \n",
    "        train_tags,\n",
    "        validation_split=0.1, \n",
    "        batch_size=batch_size, \n",
    "        epochs=epochs,\n",
    "        verbose=1,callbacks=[checkpointer, earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hb-j4R1F_qRG",
    "outputId": "e3db8281-90fe-4359-f342-9a20988a3dd3"
   },
   "outputs": [],
   "source": [
    "train_score = model.evaluate(train_tokens, train_tags,\n",
    "                             batch_size=100)\n",
    "test_score = model.evaluate(val_tokens, val_tags,\n",
    "                            batch_size=100)\n",
    "print(\"training loss:\", train_score[0], \"training accuracy\", train_score[1])\n",
    "print(\"test loss:\", test_score[0], \"test accuracy\", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hu8wQaNf_qRL"
   },
   "outputs": [],
   "source": [
    "preds = model.predict(test_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PCedBafk_qRP",
    "outputId": "9d0823a4-fc3e-4585-f507-18b60bb8bc66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950, 128)"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds, axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "jlaY1GSi_qRU"
   },
   "outputs": [],
   "source": [
    "preds_id = np.argmax(preds, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "TKeDEWkA_qRY"
   },
   "outputs": [],
   "source": [
    "preds_labels = np.array([[idx2tag[p] for p in preds1] for preds1 in preds_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksD3VSl5H2wz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "klCorkYfH29M"
   },
   "outputs": [],
   "source": [
    "val_preds = model.predict(val_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqErOu-HH29S",
    "outputId": "62ada024-af4d-4ebc-c84b-8b782350cddc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2950, 128)"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(val_preds, axis=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "8QC8lBGiH29W"
   },
   "outputs": [],
   "source": [
    "val_preds_id = np.argmax(val_preds, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "qCKOL87fH29a"
   },
   "outputs": [],
   "source": [
    "val_preds_labels = np.array([[idx2tag[p] for p in preds1] for preds1 in val_preds_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "EA7PtGzF_qRc"
   },
   "outputs": [],
   "source": [
    "val_tags_by_idx = np.argmax(val_tags, axis=2)\n",
    "val_labels = np.array([[idx2tag[p] for p in preds] for preds in val_tags_by_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "KCrKs5xN_qRf"
   },
   "outputs": [],
   "source": [
    "# Provided function to test accuracy\n",
    "# You could check the validation accuracy to select the best of your models\n",
    "def calc_accuracy(preds, tags, padding_id=\"_t_pad_\"):\n",
    "    \"\"\"\n",
    "        Input:\n",
    "            preds (np.narray): (num_data, length_sentence)\n",
    "            tags  (np.narray): (num_data, length_sentence)\n",
    "        Output:\n",
    "            Proportion of correct prediction. The padding tokens are filtered out.\n",
    "    \"\"\"\n",
    "    preds_flatten = preds.flatten()\n",
    "    tags_flatten = tags.flatten()\n",
    "    non_padding_idx = np.where(tags_flatten!=padding_id)[0]\n",
    "    \n",
    "    return sum(preds_flatten[non_padding_idx]==tags_flatten[non_padding_idx])/len(non_padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kax9aQP_qRi",
    "outputId": "c8134712-b97b-4bff-ccde-e1a651dcf341"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pred Acc: 0.5555786976771095\n"
     ]
    }
   ],
   "source": [
    "print(\"Pred Acc:\", calc_accuracy(preds_labels, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTiePY-WIDmy",
    "outputId": "b3c5bda6-9371-473a-e644-6f555c216f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Acc: 0.8905204084584454\n"
     ]
    }
   ],
   "source": [
    "print(\"Val Acc:\", calc_accuracy(val_preds_labels, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bgL703jtHKKk"
   },
   "outputs": [],
   "source": [
    "# Let's take the baseline 1 as an example, where we predict all labels as 1.\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': test_dict[\"id\"],\n",
    "                   'labels': [json.dumps(np.array(preds).tolist()) for preds in preds_labels]})\n",
    "df.to_csv('test_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "z17cEVgkHKKw",
    "outputId": "58bfc3ed-bef7-46ef-b196-e5b4645aeb34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[\"O\", \"O\", \"IMMUNE_RESPONSE\", \"IMMUNE_RESPONSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"_t_pad_\", \"_t_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"RESEARCH_ACTIVITY\", \"RESEARCH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[\"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", \"O\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>2945</td>\n",
       "      <td>[\"DATE\", \"O\", \"CORONAVIRUS\", \"O\", \"O\", \"O\", \"O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2946</td>\n",
       "      <td>[\"VIRUS\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2947</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"CHEMICAL\", \"O\", \"O\", \"DISEASE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>2948</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"CHEMICAL\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>2949</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             labels\n",
       "0        0  [\"O\", \"O\", \"IMMUNE_RESPONSE\", \"IMMUNE_RESPONSE...\n",
       "1        1  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"_t_pad_\", \"_t_...\n",
       "2        2  [\"O\", \"O\", \"O\", \"RESEARCH_ACTIVITY\", \"RESEARCH...\n",
       "3        3  [\"O\", \"O\", \"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMI...\n",
       "4        4  [\"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", \"O\",...\n",
       "...    ...                                                ...\n",
       "2945  2945  [\"DATE\", \"O\", \"CORONAVIRUS\", \"O\", \"O\", \"O\", \"O...\n",
       "2946  2946  [\"VIRUS\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", ...\n",
       "2947  2947  [\"O\", \"O\", \"O\", \"CHEMICAL\", \"O\", \"O\", \"DISEASE...\n",
       "2948  2948  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"CHEMICAL\"...\n",
       "2949  2949  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", ...\n",
       "\n",
       "[2950 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"test_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3-XBhEHIYPj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "RqVOrBkmIYe4"
   },
   "outputs": [],
   "source": [
    "# Let's take the baseline 1 as an example, where we predict all labels as 1.\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': val_dict[\"id\"],\n",
    "                   'labels': [json.dumps(np.array(preds).tolist()) for preds in val_preds_labels]})\n",
    "df.to_csv('val_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "TcEWPIhEIYfA",
    "outputId": "cccfdc29-b54c-4f05-94da-da6f85dbbd7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"GENE_OR_GENOME\", \"O\", \"C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"ORGANISM\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"DISEASE_OR_SYNDROME\", \"D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"VIRUS\", \"O\", \"WILDLIFE\", \"WIL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[\"EUKARYOTE\", \"VIRUS\", \"O\", \"O\", \"GENE_OR_GENO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>2945</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"GENE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2946</td>\n",
       "      <td>[\"O\", \"O\", \"IMMUNE_RESPONSE\", \"IMMUNE_RESPONSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2947</td>\n",
       "      <td>[\"O\", \"DATE\", \"CORONAVIRUS\", \"O\", \"O\", \"O\", \"O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>2948</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>2949</td>\n",
       "      <td>[\"CHEMICAL\", \"O\", \"O\", \"O\", \"CHEMICAL\", \"CHEMI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             labels\n",
       "0        0  [\"O\", \"O\", \"O\", \"O\", \"GENE_OR_GENOME\", \"O\", \"C...\n",
       "1        1  [\"ORGANISM\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\"...\n",
       "2        2  [\"O\", \"O\", \"O\", \"O\", \"DISEASE_OR_SYNDROME\", \"D...\n",
       "3        3  [\"O\", \"O\", \"O\", \"VIRUS\", \"O\", \"WILDLIFE\", \"WIL...\n",
       "4        4  [\"EUKARYOTE\", \"VIRUS\", \"O\", \"O\", \"GENE_OR_GENO...\n",
       "...    ...                                                ...\n",
       "2945  2945  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"GENE...\n",
       "2946  2946  [\"O\", \"O\", \"IMMUNE_RESPONSE\", \"IMMUNE_RESPONSE...\n",
       "2947  2947  [\"O\", \"DATE\", \"CORONAVIRUS\", \"O\", \"O\", \"O\", \"O...\n",
       "2948  2948  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", ...\n",
       "2949  2949  [\"CHEMICAL\", \"O\", \"O\", \"O\", \"CHEMICAL\", \"CHEMI...\n",
       "\n",
       "[2950 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"val_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLI0em4v_qRp"
   },
   "source": [
    "# Two simple models and codes for evaluation\n",
    "\n",
    "1. Predict all the tags as \"O\".\n",
    "2. Random guess\n",
    "\n",
    "You could use the `calc_accuracy` function to evaluate the accuracy of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "1VpOwTYD_qRr"
   },
   "outputs": [],
   "source": [
    "# Provided function to test accuracy\n",
    "# You could check the validation accuracy to select the best of your models\n",
    "def calc_accuracy(preds, tags, padding_id=\"_t_pad_\"):\n",
    "    \"\"\"\n",
    "        Input:\n",
    "            preds (np.narray): (num_data, length_sentence)\n",
    "            tags  (np.narray): (num_data, length_sentence)\n",
    "        Output:\n",
    "            Proportion of correct prediction. The padding tokens are filtered out.\n",
    "    \"\"\"\n",
    "    preds_flatten = preds.flatten()\n",
    "    tags_flatten = tags.flatten()\n",
    "    non_padding_idx = np.where(tags_flatten!=padding_id)[0]\n",
    "    \n",
    "    return sum(preds_flatten[non_padding_idx]==tags_flatten[non_padding_idx])/len(non_padding_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v7SGGows_qRv",
    "outputId": "f4b1d739-c3e1-484f-b581-9b3a737220bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "baseline 1, make all predictions as 1. Acc: 0.7562260387120905\n",
      "baseline 2, Random guess. Acc: 0.015568455525377604\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on the training set\n",
    "train_tags_by_idx = np.argmax(train_tags, axis=2)\n",
    "train_labels = np.array([[idx2tag[p] for p in preds] for preds in train_tags_by_idx])\n",
    "\n",
    "print(calc_accuracy(train_labels, train_labels))\n",
    "\n",
    "# Predict all labels as \"O\"\n",
    "baseline1_train_preds = np.array([[idx2tag[p] for p in preds] for preds in np.ones(train_labels.shape)])\n",
    "print(\"baseline 1, make all predictions as 1. Acc:\", \n",
    "      calc_accuracy(baseline1_train_preds, \n",
    "                    train_labels))\n",
    "\n",
    "# Randomly guess labels.\n",
    "baseline2_train_preds = np.array([[idx2tag[p] for p in preds] for preds in np.random.randint(1, len(tag_dict), train_labels.shape)]) \n",
    "print(\"baseline 2, Random guess. Acc:\", \n",
    "      calc_accuracy(baseline2_train_preds,\n",
    "                    train_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "32JV5Mr5_qRy"
   },
   "source": [
    "# Output format\n",
    "\n",
    "In this project, you should predict the NER tags for the test set tokens.\n",
    "\n",
    "The index of test set starts from 0 and ends with 2949.\n",
    "\n",
    "You should write the predictions into a .csv file, where the first column is the test indexes in ascending order, and the second column is a json format prediction list.\n",
    "\n",
    "E.g.\n",
    "\n",
    "|id|labels|\n",
    "|:--:|:--:|\n",
    "|0|`['O', 'O', 'CHEMICAL', 'VIRUS', ...]`|\n",
    "|1|`['O', 'O', 'GENE_OR_GENOME', ...]`|\n",
    "|...|...|\n",
    "\n",
    "Format requirements:\n",
    "1. The first column `id` should be an integer, in ascending order, starting from 0 and corresponding to the index in test_dict.\n",
    "2. The second column `labels` should be a dumped string using json, storing the your predictions for each token. The size of the list should be exactly 128, including padding tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBmaHpPn_qR0"
   },
   "source": [
    "### For example, this is your prediction for the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zb1TTYk5_qR1",
    "outputId": "5219109a-6461-4c7c-b928-02159bef0431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2950, 128)\n",
      "['LOC' 'EVOLUTION' 'GROUP_ATTRIBUTE' 'TISSUE' 'NORP'\n",
      " 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY' 'CELL_OR_MOLECULAR_DYSFUNCTION'\n",
      " 'PERCENT' 'CELL_FUNCTION' 'MATERIAL' 'LIVESTOCK' 'PRODUCT' 'DATE'\n",
      " 'WORK_OF_ART' 'CELL_OR_MOLECULAR_DYSFUNCTION' 'MATERIAL'\n",
      " 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS'\n",
      " 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY' 'ORDINAL' 'QUANTITY'\n",
      " 'MOLECULAR_FUNCTION' 'EVENT' 'CELL_OR_MOLECULAR_DYSFUNCTION' 'ORDINAL'\n",
      " 'EVOLUTION' 'CELL_FUNCTION' 'NORP' 'MATERIAL'\n",
      " 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS' 'PERSON' 'PERCENT'\n",
      " 'INJURY_OR_POISONING' 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS' 'EVOLUTION'\n",
      " 'IMMUNE_RESPONSE' 'ORDINAL' 'CELL_COMPONENT' 'PRODUCT'\n",
      " 'DIAGNOSTIC_PROCEDURE' 'PERSON' 'O' 'CHEMICAL' 'GPE' 'O'\n",
      " 'MOLECULAR_FUNCTION' 'DATE' 'LANGUAGE' 'INJURY_OR_POISONING'\n",
      " 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY' 'PHYSICAL_SCIENCE' 'QUANTITY'\n",
      " 'CELL_COMPONENT' 'EVENT' 'CELL_OR_MOLECULAR_DYSFUNCTION' 'VIRAL_PROTEIN'\n",
      " 'TIME' 'INDIVIDUAL_BEHAVIOR' 'SIGN_OR_SYMPTOM' 'BACTERIUM' 'PERSON'\n",
      " 'EXPERIMENTAL_MODEL_OF_DISEASE' 'SIGN_OR_SYMPTOM' 'PERCENT'\n",
      " 'INDIVIDUAL_BEHAVIOR' 'CELL' 'SOCIAL_BEHAVIOR' 'EVENT'\n",
      " 'DIAGNOSTIC_PROCEDURE' 'DISEASE_OR_SYNDROME' 'LOC' 'MONEY'\n",
      " 'DIAGNOSTIC_PROCEDURE' 'BACTERIUM' 'TIME' 'INJURY_OR_POISONING'\n",
      " 'LANGUAGE' 'BACTERIUM' 'EUKARYOTE' 'PERSON' 'ORGAN_OR_TISSUE_FUNCTION'\n",
      " 'CHEMICAL' 'LABORATORY_OR_TEST_RESULT' 'RESEARCH_ACTIVITY' 'GROUP'\n",
      " 'TISSUE' 'BODY_SUBSTANCE' 'EVENT' 'ANATOMICAL_STRUCTURE' 'BACTERIUM'\n",
      " 'CARDINAL' 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS' 'BODY_SUBSTANCE'\n",
      " 'ORDINAL' 'CELL_COMPONENT' 'FAC' 'SOCIAL_BEHAVIOR' 'ORG'\n",
      " 'ORGAN_OR_TISSUE_FUNCTION' 'LABORATORY_OR_TEST_RESULT' 'PERCENT'\n",
      " 'HUMAN-CAUSED_PHENOMENON_OR_PROCESS' 'FOOD' 'CARDINAL' 'EVOLUTION'\n",
      " 'LABORATORY_PROCEDURE' 'MACHINE_ACTIVITY' 'WILDLIFE' 'VIRUS'\n",
      " 'CELL_COMPONENT' 'CELL' 'GROUP_ATTRIBUTE' 'DISEASE_OR_SYNDROME' 'PERCENT'\n",
      " 'GOVERNMENTAL_OR_REGULATORY_ACTIVITY' 'LAW' 'MATERIAL' 'LOC' 'PERSON'\n",
      " 'PRODUCT' 'GPE' 'GENE_OR_GENOME' 'EDUCATIONAL_ACTIVITY' 'SOCIAL_BEHAVIOR'\n",
      " 'EUKARYOTE' 'THERAPEUTIC_OR_PREVENTIVE_PROCEDURE' 'WILDLIFE' 'PERSON'\n",
      " 'RESEARCH_ACTIVITY']\n"
     ]
    }
   ],
   "source": [
    "test_preds_numerical = np.random.randint(1, len(tag_dict), \n",
    "                                         (len(test_dict[\"id\"]), max_sent_length))\n",
    "test_preds = np.array([[idx2tag[p] for p in preds] for preds in test_preds_numerical])\n",
    "print(test_preds.shape)\n",
    "print(test_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "wYNcyqug_qR5"
   },
   "outputs": [],
   "source": [
    "# Let's take the baseline 1 as an example, where we predict all labels as 1.\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': test_dict[\"id\"],\n",
    "                   'labels': [json.dumps(np.array(preds).tolist()) for preds in preds_labels]})\n",
    "df.to_csv('test_preds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "26mOpQp-_qR8",
    "outputId": "58bfc3ed-bef7-46ef-b196-e5b4645aeb34"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[\"O\", \"O\", \"IMMUNE_RESPONSE\", \"IMMUNE_RESPONSE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"_t_pad_\", \"_t_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"RESEARCH_ACTIVITY\", \"RESEARCH...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[\"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", \"O\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>2945</td>\n",
       "      <td>[\"DATE\", \"O\", \"CORONAVIRUS\", \"O\", \"O\", \"O\", \"O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>2946</td>\n",
       "      <td>[\"VIRUS\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>2947</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"CHEMICAL\", \"O\", \"O\", \"DISEASE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2948</th>\n",
       "      <td>2948</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"CHEMICAL\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2949</th>\n",
       "      <td>2949</td>\n",
       "      <td>[\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             labels\n",
       "0        0  [\"O\", \"O\", \"IMMUNE_RESPONSE\", \"IMMUNE_RESPONSE...\n",
       "1        1  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"_t_pad_\", \"_t_...\n",
       "2        2  [\"O\", \"O\", \"O\", \"RESEARCH_ACTIVITY\", \"RESEARCH...\n",
       "3        3  [\"O\", \"O\", \"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMI...\n",
       "4        4  [\"O\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", \"O\",...\n",
       "...    ...                                                ...\n",
       "2945  2945  [\"DATE\", \"O\", \"CORONAVIRUS\", \"O\", \"O\", \"O\", \"O...\n",
       "2946  2946  [\"VIRUS\", \"CHEMICAL\", \"CHEMICAL\", \"CHEMICAL\", ...\n",
       "2947  2947  [\"O\", \"O\", \"O\", \"CHEMICAL\", \"O\", \"O\", \"DISEASE...\n",
       "2948  2948  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"CHEMICAL\"...\n",
       "2949  2949  [\"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", ...\n",
       "\n",
       "[2950 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"test_preds.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LTsM5zGb_qSB"
   },
   "source": [
    "# Please make your output-format exactly the same as above\n",
    "\n",
    "You could check it by playing around with the validation set with our evaluation codes `evaluate.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5U7RG9-r_qSB",
    "outputId": "810e884c-9a11-4382-e622-09df16c101b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.8905204084584454\n"
     ]
    }
   ],
   "source": [
    "# val_preds_numerical = np.random.randint(1, len(tag_dict), \n",
    "#                                          (len(val_dict[\"id\"]), max_sent_length))\n",
    "# val_preds = np.array([[idx2tag[p] for p in preds] for preds in np.ones((len(val_dict[\"id\"]), max_sent_length))])\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'id': val_dict[\"id\"],\n",
    "                   'labels': [json.dumps(np.array(preds).tolist()) for preds in val_preds_labels]})\n",
    "df.to_csv('val_preds.csv', index=False)\n",
    "\n",
    "from evaluate import evaluate\n",
    "\n",
    "print(\"val accuracy\", evaluate('val_preds.csv', \"data/val.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xHyAQW98_qSE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "playground - Copy - Copy3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
